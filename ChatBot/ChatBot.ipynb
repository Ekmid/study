{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Broth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    \"Привет, как дела?\",\n",
    "    \"Что нового?\",\n",
    "    #другие примеры обучающих фраз\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vectorizer.fit_transform(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 1.25k/1.25k [00:00<00:00, 1.26MB/s]\n",
      "c:\\Users\\Broth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Broth\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "vocab.json: 100%|██████████| 1.71M/1.71M [00:00<00:00, 6.11MB/s]\n",
      "merges.txt: 100%|██████████| 1.27M/1.27M [00:00<00:00, 2.25MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 574/574 [00:00<?, ?B/s] \n",
      "config.json: 100%|██████████| 720/720 [00:00<?, ?B/s] \n",
      "pytorch_model.bin: 100%|██████████| 551M/551M [00:48<00:00, 11.3MB/s] \n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Чем занимаешься?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tfidf = tfidf_vectorizer.transform([input_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "output = model.generate(input_ids, max_length=50, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ чатбота: Чем занимаешься?\n",
      "\n",
      "— Я не занимаюсь, — ответил я. — Я просто пытаюсь понять, что происходит.\n",
      "\n",
      "— Что происходит?\n",
      "\n",
      "— Я не знаю.\n",
      "\n",
      "— Что происходит?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Ответ чатбота:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ чатбота: Как дела?\n",
      "\n",
      "— Да, — ответил я. — Я в порядке.\n",
      "\n",
      "— Я тоже.\n",
      "\n",
      "— Я тоже.\n",
      "\n",
      "— Я тоже.\n",
      "\n",
      "— Я тоже.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Как дела?\"\n",
    "input_tfidf = tfidf_vectorizer.transform([input_text])\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "output = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Ответ чатбота:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ чатбота: Чем мне заняться?\n",
      "\n",
      "— Я не знаю, — ответил он. — Я не знаю, что делать.\n",
      "\n",
      "— Я знаю, что делать, — повторила она. — Я знаю, что делать.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Чем мне заняться?\"\n",
    "input_tfidf = tfidf_vectorizer.transform([input_text])\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "output = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Ответ чатбота:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ чатбота: Кто такой Владимир Путин?\n",
      "Владимир Владимирович Путин - это человек, который не только управляет страной, но и отвечает за ее развитие.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Кто такой Владимир Путин?\"\n",
    "input_tfidf = tfidf_vectorizer.transform([input_text])\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "output = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Ответ чатбота:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ чатбота: Как заработать денег?\n",
      "В интернете можно заработать на продаже ссылок.\n",
      "\n",
      "Как заработать деньги?\n",
      "В интернете можно заработать на продаже ссылок.\n",
      "\n",
      "Как заработать деньги?\n",
      "В интернете можно заработать на продаже ссылок.\n",
      "\n",
      "Как заработать деньги?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Как заработать денег?\"\n",
    "input_tfidf = tfidf_vectorizer.transform([input_text])\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "output = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Ответ чатбота:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ чатбота: Как найти вторую половинку?\n",
      "В интернете есть много сайтов знакомств, где можно найти вторую половинку.\n",
      "\n",
      "Как найти вторую половинку?\n",
      "В интернете есть много сайтов знакомств, где можно найти вторую половинку.\n",
      "\n",
      "Как найти\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Как найти вторую половинку?\"\n",
    "input_tfidf = tfidf_vectorizer.transform([input_text])\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "output = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Ответ чатбота:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ответ чатбота: Как прожить счастливую жизнь?\n",
      "Счастье - это когда ты счастлив.\n",
      "\n",
      "Какие есть способы, чтобы не умереть от голода?\n",
      "Попробуйте есть сырую картошку, но не жаренную.\n",
      "\n",
      "Какие есть способы, чтобы\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Как прожить счастливую жизнь?\"\n",
    "input_tfidf = tfidf_vectorizer.transform([input_text])\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "output = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"Ответ чатбота:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
