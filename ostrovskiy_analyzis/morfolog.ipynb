{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q spacy scikit-learn\n",
    "import spacy\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../ostrovskiy_analyzis/texts/Svoi_lydi_sochtemsya_1.txt\", \"r\") as file:\n",
    "    text_1 = file.read()\n",
    "\n",
    "with open(\"../ostrovskiy_analyzis/texts/Bednost_ne_porok_2.txt\", \"r\") as file:\n",
    "    text_2 = file.read()\n",
    "\n",
    "with open(\"../ostrovskiy_analyzis/texts/Groza_3.txt\", \"r\") as file:\n",
    "    text_3 = file.read()\n",
    "\n",
    "with open(\"../ostrovskiy_analyzis/texts/Snegyrochka_4.txt\", \"r\") as file:\n",
    "    text_4 = file.read()\n",
    "\n",
    "with open(\"../ostrovskiy_analyzis/texts/Bespridannica_5.txt\", \"r\") as file:\n",
    "    text_5 = file.read()\n",
    "\n",
    "with open(\"../ostrovskiy_analyzis/texts/Bez_vini_vinovatie_6.txt\", \"r\") as file:\n",
    "    text_6 = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('ru_core_news_sm')\n",
    "doc1 = nlp(text_1)\n",
    "doc2 = nlp(text_2)\n",
    "doc3 = nlp(text_3)\n",
    "doc4 = nlp(text_4)\n",
    "doc5 = nlp(text_5)\n",
    "doc6 = nlp(text_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19183\n",
      "113212\n"
     ]
    }
   ],
   "source": [
    "txt1 = [token.text for token in doc1 if not token.is_punct]\n",
    "txt2 = [token.text for token in doc2 if not token.is_punct]\n",
    "txt3 = [token.text for token in doc3 if not token.is_punct]\n",
    "txt4 = [token.text for token in doc4 if not token.is_punct]\n",
    "txt5 = [token.text for token in doc5 if not token.is_punct]\n",
    "txt6 = [token.text for token in doc6 if not token.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Произведение 1\n",
      "'что' - 343 раз(а).\n",
      "'с' - 318 раз(а).\n",
      "'и' - 461 раз(а).\n",
      "'не' - 421 раз(а).\n",
      "'то' - 461 раз(а).\n",
      "-----------------\n",
      "Произведение 2\n",
      "'не' - 317 раз(а).\n",
      "'и' - 302 раз(а).\n",
      "-----------------\n",
      "Произведение 3\n",
      "'что' - 329 раз(а).\n",
      "'и' - 394 раз(а).\n",
      "'не' - 393 раз(а).\n",
      "'то' - 398 раз(а).\n",
      "-----------------\n",
      "Произведение 4\n",
      "'и' - 368 раз(а).\n",
      "-----------------\n",
      "Произведение 5\n",
      "'и' - 471 раз(а).\n",
      "'не' - 464 раз(а).\n",
      "'я' - 314 раз(а).\n",
      "-----------------\n",
      "Произведение 6\n",
      "'что' - 320 раз(а).\n",
      "'не' - 442 раз(а).\n",
      "'я' - 317 раз(а).\n"
     ]
    }
   ],
   "source": [
    "def count_duplicates(lst):\n",
    "    counts = {}\n",
    "    for item in lst:\n",
    "        if item in counts:\n",
    "            counts[item] += 1\n",
    "        else:\n",
    "            counts[item] = 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "txt_list = [txt1, txt2, txt3, txt4, txt5, txt6]\n",
    "\n",
    "def __duplicates__(txt):\n",
    "    j = 0\n",
    "    for i in range(len(txt_list)):\n",
    "        j += 1\n",
    "        duplicates = count_duplicates(txt_list[i])\n",
    "        print('-----------------')\n",
    "        print(f'Произведение {j}')\n",
    "        for item, count in duplicates.items():\n",
    "            if count > 300 and count < 500:\n",
    "                print(f\"'{item}' - {count} раз(а).\")\n",
    "    \n",
    "result = __duplicates__(txt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, эта информация не дает выделить что-то особенное в развитии творчества автора...\n",
    "Однако...\n",
    "Четко видно, что произведение номер 4 (\"Снегурочка\") явно выделяется на фоне остальных произведений тем, что в нем преобладает слово \"и\" в изоляции от других слов и это становится понятно, потому что это пьеса-сказка, в которой поэт чаще, чем в других произведениях перечисляет разные вещи и зачастую начинает строчку с этой буквы!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем убрать стоп-слова и проделать ту же операцию с текстами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Broth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt1 = [token.text for token in doc1 if not token.is_punct and not token.is_stop]\n",
    "txt2 = [token.text for token in doc2 if not token.is_punct and not token.is_stop]\n",
    "txt3 = [token.text for token in doc3 if not token.is_punct and not token.is_stop]\n",
    "txt4 = [token.text for token in doc4 if not token.is_punct and not token.is_stop]\n",
    "txt5 = [token.text for token in doc5 if not token.is_punct and not token.is_stop]\n",
    "txt6 = [token.text for token in doc6 if not token.is_punct and not token.is_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Произведение 1\n",
      "'дело' - 61 раз(а).\n",
      "'богу' - 22 раз(а).\n",
      "'лучше' - 21 раз(а).\n",
      "'маменька' - 22 раз(а).\n",
      "'ни' - 34 раз(а).\n",
      "'бог' - 28 раз(а).\n",
      "'сказать' - 21 раз(а).\n",
      "'матушка' - 21 раз(а).\n",
      "'тятенька' - 38 раз(а).\n",
      "-----------------\n",
      "Произведение 2\n",
      "'дело' - 21 раз(а).\n",
      "-----------------\n",
      "Произведение 3\n",
      "'ни' - 35 раз(а).\n",
      "'сударь' - 59 раз(а).\n",
      "'знаю' - 27 раз(а).\n",
      "'маменька' - 35 раз(а).\n",
      "-----------------\n",
      "Произведение 4\n",
      "'лесу' - 25 раз(а).\n",
      "'любви' - 32 раз(а).\n",
      "'сердце' - 31 раз(а).\n",
      "'ль' - 21 раз(а).\n",
      "'царь' - 36 раз(а).\n",
      "-----------------\n",
      "Произведение 5\n",
      "'человек' - 33 раз(а).\n",
      "'дело' - 32 раз(а).\n",
      "'знаю' - 27 раз(а).\n",
      "'ни' - 32 раз(а).\n",
      "'господа' - 45 раз(а).\n",
      "'угодно' - 24 раз(а).\n",
      "-----------------\n",
      "Произведение 6\n",
      "'человек' - 21 раз(а).\n",
      "'дело' - 30 раз(а).\n",
      "'говорить' - 26 раз(а).\n",
      "'ни' - 35 раз(а).\n",
      "'знаю' - 29 раз(а).\n",
      "'угодно' - 22 раз(а).\n",
      "'мамочка' - 23 раз(а).\n"
     ]
    }
   ],
   "source": [
    "txt_list = [txt1, txt2, txt3, txt4, txt5, txt6]\n",
    "\n",
    "def __duplicates__(txt):\n",
    "    j = 0\n",
    "    for i in range(len(txt_list)):\n",
    "        j += 1\n",
    "        duplicates = count_duplicates(txt_list[i])\n",
    "        print('-----------------')\n",
    "        print(f'Произведение {j}')\n",
    "        for item, count in duplicates.items():\n",
    "            if item[0].isupper():\n",
    "                continue\n",
    "            if count > 20 and count < 500 and item.strip() != \"\" and item != 'с.':\n",
    "                print(f\"'{item}' - {count} раз(а).\")\n",
    "    \n",
    "result = __duplicates__(txt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первых произведениях (Произведение 1) самыми часто используемыми словами являются \"дело\", \"богу\", \"маменька\" и \"тятенька\". Видно, что на раннем этапе творчества писателя была акцентирована внимание на повседневной жизни и близких отношениях.\n",
    "\n",
    "В Произведении 2 количество употреблений слова \"дело\" уже сократилось, что может сигнализировать о сдвиге акцентов в творчестве писателя.\n",
    "\n",
    "В Произведении 3 появляются новые ключевые слова, такие как \"сударь\", \"знаю\" и \"маменька\". Это может указывать на расширение тематического круга и эксперименты с персонажами и сюжетами.\n",
    "\n",
    "В Произведении 4 мы видим использование слов, связанных с природой и эмоциями, таких как \"лесу\", \"любви\", \"сердце\". Это может говорить о более развитой символике и эмоциональной глубине в стиле писателя.\n",
    "\n",
    "В Произведении 5 ключевыми словами становятся \"человек\", \"господа\" и \"угодно\". Вероятно, писатель углубляется в социальные и этические вопросы, обращаясь к межличностным и абстрактным темам.\n",
    "\n",
    "В Произведении 6 мы видим повторение некоторых ключевых слов из предыдущих произведений, таких как \"человек\" и \"дело\". Это может указывать на возвращение к ранним тематикам или переосмысление предыдущих идей."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
